{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import destvi_utils\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scanpy as sc\n",
    "import anndata as ad\n",
    "import pandas as pd\n",
    "import scipy\n",
    "from scvi.model import CondSCVI, DestVI\n",
    "from skmisc.loess import loess\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_adata=sc.read_h5ad('scRNA_mouse_PDAC_day30.h5ad')\n",
    "st_adata=sc.read_visium('GSM6727528/outs',source_image_path='.GSM6727528/outs/spatial')\n",
    "st_filtered=pd.read_csv('SelectedSpots.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset st data\n",
    "st_adata.var_names_make_unique()\n",
    "st_adata=st_adata[st_filtered['x'],]\n",
    "st_adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NB: sc_adata contains raw counts\n",
    "sc.pp.filter_genes(sc_adata, min_counts=10)\n",
    "G = 2000\n",
    "sc_adata.layers[\"counts\"] = sc_adata.X.copy()\n",
    "sc.pp.highly_variable_genes(sc_adata, n_top_genes=G, subset=True, layer=\"counts\", flavor=\"seurat_v3\")\n",
    "sc.pp.normalize_total(sc_adata, target_sum=10e4)\n",
    "sc.pp.log1p(sc_adata)\n",
    "sc_adata.raw = sc_adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spatial data\n",
    "st_adata.layers[\"counts\"] = st_adata.X.copy()\n",
    "\n",
    "sc.pp.normalize_total(st_adata, target_sum=10e4)\n",
    "sc.pp.log1p(st_adata)\n",
    "st_adata.raw = st_adata\n",
    "\n",
    "loc=st_adata.obsm[\"spatial\"]\n",
    "st_adata.obsm[\"spatial\"]=loc.astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter genes to be the same on the spatial and sc data\n",
    "intersect = np.intersect1d(sc_adata.var_names, st_adata.var_names)\n",
    "st_adata = st_adata[:, intersect].copy()\n",
    "sc_adata = sc_adata[:, intersect].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the scLMV\n",
    "CondSCVI.setup_anndata(sc_adata, layer=\"counts\", labels_key=\"Annotation\")\n",
    "sc_model = CondSCVI(sc_adata, weight_obs=False)\n",
    "sc_model.view_anndata_setup()\n",
    "sc_model.train()\n",
    "\n",
    "sc_model.history[\"elbo_train\"].iloc[5:].plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deconvolution\n",
    "DestVI.setup_anndata(st_adata, layer=\"counts\")\n",
    "st_model = DestVI.from_rna_model(st_adata, sc_model)\n",
    "st_model.view_anndata_setup()\n",
    "st_model.train(max_epochs=2500)\n",
    "st_model.history[\"elbo_train\"].iloc[10:].plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get proportions\n",
    "st_adata.obsm[\"proportions\"] = st_model.get_proportions()\n",
    "st_adata.obsm[\"proportions\"].to_csv('CellProp_DestVI.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct_thresholds = destvi_utils.automatic_proportion_threshold(st_adata,  kind_threshold=\"primary\")\n",
    "ct_thresholds['MonoMacro'] = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ct, g in st_model.get_gamma().items():\n",
    "    st_adata.obsm[f\"{ct}_gamma\"] = g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD FUNCTIONS FROM destvi_utils\n",
    "import anndata as ad\n",
    "import hotspot\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.interpolate import splev, splrep\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "\n",
    "def _prettify_axis(ax, spatial=False):\n",
    "    # Hide the right and top spines\n",
    "    ax.spines[\"right\"].set_visible(False)\n",
    "    ax.spines[\"top\"].set_visible(False)\n",
    "    # Only show ticks on the left and bottom spines\n",
    "    ax.yaxis.set_ticks_position(\"left\")\n",
    "    ax.xaxis.set_ticks_position(\"bottom\")\n",
    "    if spatial:\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.xlabel(\"Spatial1\")\n",
    "        plt.ylabel(\"Spatial2\")\n",
    "\n",
    "\n",
    "def _form_stacked_quantiles(data, N=100):\n",
    "    quantiles = np.quantile(data, np.linspace(0, 1, N, endpoint=False))\n",
    "    return quantiles, np.vstack([_flatten(data, q) for q in quantiles])\n",
    "\n",
    "\n",
    "def _flatten(x, threshold):\n",
    "    return (x > threshold) * x\n",
    "\n",
    "\n",
    "def _smooth_get_critical_points(x, noisy_data, k=5, s=0.1):\n",
    "    f = splrep(x, noisy_data, k=5, s=1)\n",
    "    smoothed = splev(x, f)\n",
    "    derivative = splev(x, f, der=1)\n",
    "    sign_2nd = splev(x, f, der=2) > 0\n",
    "    curvature = splev(x, f, der=3)\n",
    "    return noisy_data, smoothed, derivative, sign_2nd, curvature\n",
    "\n",
    "\n",
    "def _get_autocorrelations(st_adata, stacked_quantiles, quantiles):\n",
    "    # create Anndata and run hotspot\n",
    "    adata = ad.AnnData(stacked_quantiles.T)\n",
    "    adata.obs_names = st_adata.obs.index\n",
    "    adata.var_names = [str(i) for i in quantiles]\n",
    "    adata.obsm[\"spatial\"] = st_adata.obsm[\"spatial\"]\n",
    "    hs = hotspot.Hotspot(adata, model=\"none\", latent_obsm_key=\"spatial\")\n",
    "    hs.create_knn_graph(\n",
    "        weighted_graph=True,\n",
    "        n_neighbors=10,\n",
    "    )\n",
    "    hs_results = hs.compute_autocorrelations(jobs=1)\n",
    "    index = np.array([float(i) for i in hs_results.index.values])\n",
    "    return index, hs_results[\"Z\"].values\n",
    "\n",
    "\n",
    "def _get_laplacian(s, pi):\n",
    "    N = s.shape[0]\n",
    "    dist_table = pdist(s)\n",
    "    bandwidth = np.median(dist_table)\n",
    "    sigma = 0.5 * bandwidth**2\n",
    "\n",
    "    l2_square = squareform(dist_table) ** 2\n",
    "    D = np.exp(-l2_square / sigma) * np.dot(pi, pi.T)\n",
    "    L = -D\n",
    "    sum_D = np.sum(D, axis=1)\n",
    "    for i in range(N):\n",
    "        L[i, i] = sum_D[i]\n",
    "    return L\n",
    "\n",
    "\n",
    "def _get_spatial_components(locations, proportions, data):\n",
    "    # find top two spatial principal vectors\n",
    "    # form laplacian\n",
    "    L = _get_laplacian(locations, proportions)\n",
    "    # center data\n",
    "    transla_ = data.copy()\n",
    "    transla_ -= np.mean(transla_, axis=0)\n",
    "    # get eigenvectors\n",
    "    A = np.dot(transla_.T, np.dot(L, transla_))\n",
    "    w, v = np.linalg.eig(A)\n",
    "    # don't forget to sort them...\n",
    "    idx = np.argsort(w)[::-1]\n",
    "    vec = v[:, idx][:, :]\n",
    "    return vec\n",
    "\n",
    "\n",
    "def _vcorrcoef(X, y):\n",
    "    Xm = np.reshape(np.mean(X, axis=1), (X.shape[0], 1))\n",
    "    ym = np.mean(y)\n",
    "    r_num = np.sum((X - Xm) * (y - ym), axis=1)\n",
    "    r_den = np.sqrt(np.sum((X - Xm) ** 2, axis=1) * np.sum((y - ym) ** 2))\n",
    "    r = np.divide(\n",
    "        r_num,\n",
    "        r_den,\n",
    "        out=np.zeros_like(\n",
    "            r_num,\n",
    "        ),\n",
    "        where=r_den != 0,\n",
    "    )\n",
    "    return r\n",
    "\n",
    "\n",
    "def _get_delta(lfc):\n",
    "    return np.max(\n",
    "        np.abs(GaussianMixture(n_components=3).fit(np.array(lfc).reshape(-1, 1)).means_)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get 5 Spatial PCs\n",
    "gamma = st_model.get_gamma(return_numpy=True)\n",
    "filter_ = st_adata.obsm[\"proportions\"]['MonoMacro'].values > ct_thresholds['MonoMacro']\n",
    "locations = st_adata.obsm[\"spatial\"][filter_]\n",
    "proportions = st_adata.obsm[\"proportions\"]['MonoMacro'].values[filter_]\n",
    "ct_index = np.where('MonoMacro' == st_model.cell_type_mapping)[0][0]\n",
    "data = gamma[:, :, ct_index][filter_]\n",
    "\n",
    "vec=get_spatial_components(locations, proportions, data)[:,:]\n",
    "projection = np.dot(data - np.mean(data, 0), vec)\n",
    "\n",
    "SpatialPCs=pd.DataFrame(projection)\n",
    "SpatialPCs.index=st_adata.obs_names[filter_]\n",
    "SpatialPCs.to_csv('SpatialPCs_MonoMacro.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get genes whose expression correlates with Spatial PCs\n",
    "sc_adata_slice = sc_adata[sc_adata.obs[\"Annotation\"] == 'MonoMacro']\n",
    "is_sparse = scipy.sparse.issparse(sc_adata_slice.X)\n",
    "normalized_counts = sc_adata_slice.X.A if is_sparse else sc_adata_slice.X\n",
    "\n",
    "indices_ct = np.where(sc_adata.obs[\"Annotation\"] == 'MonoMacro')[0]\n",
    "sc_latent = sc_model.get_latent_representation(indices=indices_ct)\n",
    "sc_projection = np.dot(sc_latent - np.mean(sc_latent,0), vec)\n",
    "\n",
    "r = _vcorrcoef(normalized_counts.T, sc_projection[:, 0])\n",
    "ranking = np.argsort(r)\n",
    "PC1Pos=pd.DataFrame(r[ranking][::-1][:50])\n",
    "PC1Pos.index=list(st_adata.var.index[ranking[::-1][:50]])\n",
    "\n",
    "PC1Neg=pd.DataFrame(r[ranking][:50])\n",
    "PC1Neg.index=list(st_adata.var.index[ranking[:50]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generate Expression Matrix for CellType\n",
    "\n",
    "# impute \n",
    "imp_ge = st_model.get_scale_for_ct(\"MonoMacro\", indices=np.where(filter_)[0]).values\n",
    "\n",
    "# get statistics\n",
    "avg_library_size = np.mean(np.sum(st_adata.layers[\"counts\"], axis=1).A.flatten())\n",
    "exp_px_o = st_model.module.px_o.detach().exp().cpu().numpy()\n",
    "mean = avg_library_size * imp_ge\n",
    "\n",
    "# create distribution\n",
    "concentration = torch.tensor(avg_library_size * imp_ge / exp_px_o)\n",
    "rate = torch.tensor(1. / exp_px_o)\n",
    "\n",
    "# generate\n",
    "for j in [1,2,3,4,5,6]:\n",
    "    N = 1\n",
    "    simulated = torch.distributions.Gamma(concentration=concentration, rate = rate).sample((N,)).cpu().numpy()\n",
    "    simulated = np.log(simulated + 1)\n",
    "    simulated = simulated.reshape((-1, simulated.shape[-1]))\n",
    "    simulated=pd.DataFrame(simulated, index=st_adata.obs['_indices'][np.where(filter_)[0]].index, columns=st_adata.var['gene_ids'].index)\n",
    "    simulated.to_csv(f\"Simulation_{j}_MonoMacro.csv\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
